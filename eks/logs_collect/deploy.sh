#!/bin/bash

# Logs Collect é¡¹ç›®éƒ¨ç½²è„šæœ¬
# åŠŸèƒ½ï¼šåˆ›å»ºEKSé›†ç¾¤ã€éƒ¨ç½²æµ‹è¯•åº”ç”¨ã€é…ç½®ALBã€åˆ›å»ºOpenSearchã€éƒ¨ç½²Fluent-bit

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ç¯å¢ƒå˜é‡
check_env_vars() {
    log_info "æ£€æŸ¥ç¯å¢ƒå˜é‡..."
    
    required_vars=("AWS_ACCOUNT_ID" "DOMAIN_NAME" "CERTIFICATE_ARN" "OPENSEARCH_PASSWORD")
    missing_vars=()
    
    for var in "${required_vars[@]}"; do
        if [ -z "${!var}" ]; then
            missing_vars+=("$var")
        fi
    done
    
    if [ ${#missing_vars[@]} -ne 0 ]; then
        log_error "ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡ï¼š"
        for var in "${missing_vars[@]}"; do
            echo "  - $var"
        done
        echo ""
        echo "è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š"
        echo "export AWS_ACCOUNT_ID=\"your-account-id\""
        echo "export DOMAIN_NAME=\"your-domain.com\""
        echo "export CERTIFICATE_ARN=\"arn:aws:acm:us-east-1:account:certificate/cert-id\""
        echo "export OPENSEARCH_PASSWORD=\"your-secure-password\""
        exit 1
    fi
    
    log_success "ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥å¿…éœ€å·¥å…·
check_tools() {
    log_info "æ£€æŸ¥å¿…éœ€å·¥å…·..."
    
    tools=("aws" "eksctl" "kubectl" "helm")
    missing_tools=()
    
    for tool in "${tools[@]}"; do
        if ! command -v "$tool" &> /dev/null; then
            missing_tools+=("$tool")
        fi
    done
    
    if [ ${#missing_tools[@]} -ne 0 ]; then
        log_error "ç¼ºå°‘å¿…éœ€å·¥å…·ï¼š"
        for tool in "${missing_tools[@]}"; do
            echo "  - $tool"
        done
        exit 1
    fi
    
    log_success "å·¥å…·æ£€æŸ¥é€šè¿‡"
}

# 1. åˆ›å»ºEKSé›†ç¾¤
create_eks_cluster() {
    log_info "æ­¥éª¤1: åˆ›å»ºEKSé›†ç¾¤ (ç‰ˆæœ¬1.33)..."
    
    CLUSTER_NAME="logs-collect-cluster"
    REGION="us-east-1"
    
    if eksctl get cluster --name $CLUSTER_NAME --region $REGION >/dev/null 2>&1; then
        log_warning "EKSé›†ç¾¤ $CLUSTER_NAME å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º"
        
        # æ£€æŸ¥é›†ç¾¤ç‰ˆæœ¬
        CURRENT_VERSION=$(aws eks describe-cluster --name $CLUSTER_NAME --region $REGION --query 'cluster.version' --output text)
        log_info "å½“å‰é›†ç¾¤ç‰ˆæœ¬: $CURRENT_VERSION"
        
        if [ "$CURRENT_VERSION" != "1.33" ]; then
            log_warning "é›†ç¾¤ç‰ˆæœ¬ä¸æ˜¯1.33ï¼Œå»ºè®®å‡çº§é›†ç¾¤ç‰ˆæœ¬"
        fi
    else
        log_info "ä½¿ç”¨è‡ªåŠ¨æ¨¡å¼åˆ›å»ºEKSé›†ç¾¤ $CLUSTER_NAME (ç‰ˆæœ¬1.33)..."
        log_info "è¿™å°†è‡ªåŠ¨é…ç½®VPCã€å­ç½‘ã€å®‰å…¨ç»„å’Œæ‰˜ç®¡èŠ‚ç‚¹ç»„..."
        
        eksctl create cluster -f cluster-config.yaml
        
        log_success "EKSé›†ç¾¤åˆ›å»ºå®Œæˆ"
        log_info "é›†ç¾¤ç‰¹æ€§ï¼š"
        log_info "  âœ“ Kubernetesç‰ˆæœ¬: 1.33"
        log_info "  âœ“ æ‰˜ç®¡èŠ‚ç‚¹ç»„: è‡ªåŠ¨æ‰©ç¼©å®¹"
        log_info "  âœ“ VPC: è‡ªåŠ¨åˆ›å»º"
        log_info "  âœ“ æ’ä»¶: è‡ªåŠ¨å®‰è£…æœ€æ–°ç‰ˆæœ¬"
        log_info "  âœ“ Fargate: å·²é…ç½®"
    fi
    
    # æ›´æ–°kubeconfig
    aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
    log_success "kubeconfigå·²æ›´æ–°"
    
    # éªŒè¯é›†ç¾¤çŠ¶æ€
    log_info "éªŒè¯é›†ç¾¤çŠ¶æ€..."
    kubectl get nodes
    kubectl get pods --all-namespaces | head -10
}

# 2. éƒ¨ç½²æµ‹è¯•åº”ç”¨
deploy_test_app() {
    log_info "æ­¥éª¤2: éƒ¨ç½²æ—¥å¿—é‡‡é›†æµ‹è¯•åº”ç”¨..."
    
    # æ›¿æ¢ç¯å¢ƒå˜é‡å¹¶åº”ç”¨é…ç½®
    envsubst < test-app-deployment.yaml | kubectl apply -f -
    
    # ç­‰å¾…Podå°±ç»ª
    log_info "ç­‰å¾…æµ‹è¯•åº”ç”¨Podå°±ç»ª..."
    kubectl wait --for=condition=ready pod -l app=log-generator -n logs-collect --timeout=300s
    
    log_success "æµ‹è¯•åº”ç”¨éƒ¨ç½²å®Œæˆ"
}

# 3. éƒ¨ç½²ALB Ingress Controllerå’Œé…ç½®
deploy_alb_ingress() {
    log_info "æ­¥éª¤3: éƒ¨ç½²ALB Ingress Controller..."
    
    CLUSTER_NAME="logs-collect-cluster"
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»é€šè¿‡eksctlé…ç½®äº†æœåŠ¡è´¦æˆ·
    if kubectl get serviceaccount aws-load-balancer-controller -n kube-system >/dev/null 2>&1; then
        log_info "AWS Load Balancer ControlleræœåŠ¡è´¦æˆ·å·²å­˜åœ¨ï¼ˆé€šè¿‡eksctlé…ç½®ï¼‰"
    else
        # æ‰‹åŠ¨åˆ›å»ºIAMè§’è‰²å’Œç­–ç•¥ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        log_info "åˆ›å»ºALB Controller IAMè§’è‰²..."
        
        # ä¸‹è½½æœ€æ–°IAMç­–ç•¥
        curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.8.1/docs/install/iam_policy.json
        
        # åˆ›å»ºIAMç­–ç•¥
        aws iam create-policy \
            --policy-name AWSLoadBalancerControllerIAMPolicy \
            --policy-document file://iam_policy.json || true
        
        # åˆ›å»ºIAMè§’è‰²
        eksctl create iamserviceaccount \
            --cluster=$CLUSTER_NAME \
            --namespace=kube-system \
            --name=aws-load-balancer-controller \
            --role-name AmazonEKSLoadBalancerControllerRole \
            --attach-policy-arn=arn:aws:iam::$AWS_ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy \
            --approve || true
    fi
    
    # å®‰è£…AWS Load Balancer Controller
    log_info "å®‰è£…AWS Load Balancer Controller (æœ€æ–°ç‰ˆæœ¬)..."
    helm repo add eks https://aws.github.io/eks-charts
    helm repo update
    
    # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
    if helm list -n kube-system | grep -q aws-load-balancer-controller; then
        log_info "å‡çº§AWS Load Balancer Controller..."
        helm upgrade aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=$CLUSTER_NAME \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=us-east-1 \
            --set vpcId=$(aws eks describe-cluster --name $CLUSTER_NAME --query "cluster.resourcesVpcConfig.vpcId" --output text)
    else
        log_info "å®‰è£…AWS Load Balancer Controller..."
        helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=$CLUSTER_NAME \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=us-east-1 \
            --set vpcId=$(aws eks describe-cluster --name $CLUSTER_NAME --query "cluster.resourcesVpcConfig.vpcId" --output text)
    fi
    
    # ç­‰å¾…Controllerå°±ç»ª
    log_info "ç­‰å¾…AWS Load Balancer Controllerå°±ç»ª..."
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s
    
    # éƒ¨ç½²Ingress
    log_info "éƒ¨ç½²ALB Ingress..."
    envsubst < ingress.yaml | kubectl apply -f -
    
    # ç­‰å¾…ALBåˆ›å»º
    log_info "ç­‰å¾…ALBåˆ›å»ºå®Œæˆï¼ˆè¿™å¯èƒ½éœ€è¦2-3åˆ†é’Ÿï¼‰..."
    sleep 30
    
    log_success "ALB Ingresséƒ¨ç½²å®Œæˆ"
}

# 4. åˆ›å»ºOpenSearchåŸŸ
create_opensearch_domain() {
    log_info "æ­¥éª¤4: åˆ›å»ºOpenSearchåŸŸ..."
    
    DOMAIN_NAME="logs-collect-domain-v2"
    REGION="us-east-1"
    
    log_info "ğŸ“‹ ä½¿ç”¨æœ€æ–°é…ç½®ï¼š"
    echo "  - å¼•æ“ç‰ˆæœ¬: OpenSearch 2.19 (æœ€æ–°)"
    echo "  - å®ä¾‹ç±»å‹: r7g.large.search (ARM Graviton3)"
    echo "  - æ•°æ®èŠ‚ç‚¹: 3 ä¸ª"
    echo "  - å­˜å‚¨: GP3 300 GiB"
    echo "  - ç½‘ç»œ: Public access, IPv4"
    echo "  - ç²¾ç»†è®¿é—®æ§åˆ¶: å¯ç”¨ (ç”¨æˆ·åå¯†ç è®¤è¯)"
    echo "  - åŠ å¯†: å…¨é¢å¯ç”¨"
    
    # æ£€æŸ¥åŸŸæ˜¯å¦å·²å­˜åœ¨
    if aws opensearch describe-domain --domain-name $DOMAIN_NAME --region $REGION >/dev/null 2>&1; then
        log_warning "OpenSearchåŸŸ $DOMAIN_NAME å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º"
    else
        log_info "åˆ›å»ºOpenSearchåŸŸ $DOMAIN_NAME..."
        
        # åˆ›å»ºOpenSearchåŸŸ - å¯ç”¨ç”¨æˆ·åå¯†ç è®¤è¯
        aws opensearch create-domain \
            --domain-name $DOMAIN_NAME \
            --engine-version "OpenSearch_2.19" \
            --cluster-config '{
                "InstanceType": "r7g.large.search",
                "InstanceCount": 3,
                "DedicatedMasterEnabled": false,
                "ZoneAwarenessEnabled": false,
                "WarmEnabled": false,
                "ColdStorageOptions": {
                    "Enabled": false
                },
                "MultiAZWithStandbyEnabled": false
            }' \
            --ebs-options '{
                "EBSEnabled": true,
                "VolumeType": "gp3",
                "VolumeSize": 300,
                "Iops": 3000,
                "Throughput": 125
            }' \
            --access-policies '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"AWS":"*"},"Action":"es:*","Resource":"arn:aws:opensearch:'$REGION':'$AWS_ACCOUNT_ID':domain/'$DOMAIN_NAME'/*"}]}' \
            --domain-endpoint-options '{
                "EnforceHTTPS": true,
                "TLSSecurityPolicy": "Policy-Min-TLS-1-2-2019-07",
                "CustomEndpointEnabled": false
            }' \
            --advanced-security-options '{
                "Enabled": true,
                "InternalUserDatabaseEnabled": true,
                "AnonymousAuthEnabled": false,
                "MasterUserOptions": {
                    "MasterUserName": "admin",
                    "MasterUserPassword": "'$OPENSEARCH_PASSWORD'"
                }
            }' \
            --encryption-at-rest-options '{
                "Enabled": true
            }' \
            --node-to-node-encryption-options '{
                "Enabled": true
            }' \
            --advanced-options '{
                "override_main_response_version": "false",
                "rest.action.multi.allow_explicit_index": "true"
            }' \
            --snapshot-options '{
                "AutomatedSnapshotStartHour": 0
            }' \
            --auto-tune-options '{
                "DesiredState": "DISABLED",
                "UseOffPeakWindow": false
            }' \
            --software-update-options '{
                "AutoSoftwareUpdateEnabled": false
            }' \
            --tag-list '[
                {
                    "Key": "Environment",
                    "Value": "production"
                },
                {
                    "Key": "Project", 
                    "Value": "logs-collect"
                },
                {
                    "Key": "Version",
                    "Value": "v2"
                },
                {
                    "Key": "ManagedBy",
                    "Value": "kubernetes"
                }
            ]' \
            --region $REGION
        
        log_info "ç­‰å¾…OpenSearchåŸŸåˆ›å»ºå®Œæˆï¼ˆè¿™å¯èƒ½éœ€è¦15-20åˆ†é’Ÿï¼‰..."
        
        # ç­‰å¾…åŸŸå˜ä¸ºå¯ç”¨çŠ¶æ€
        while true; do
            STATUS=$(aws opensearch describe-domain --domain-name $DOMAIN_NAME --region $REGION --query 'DomainStatus.DomainProcessingStatus' --output text 2>/dev/null)
            ENDPOINT=$(aws opensearch describe-domain --domain-name $DOMAIN_NAME --region $REGION --query 'DomainStatus.Endpoint' --output text 2>/dev/null)
            
            if [ "$STATUS" = "Active" ] && [ "$ENDPOINT" != "None" ]; then
                log_success "OpenSearchåŸŸåˆ›å»ºå®Œæˆï¼"
                break
            else
                echo "â³ åŸŸçŠ¶æ€: $STATUS, ç«¯ç‚¹: $ENDPOINT - ç­‰å¾…30ç§’åé‡è¯•..."
                sleep 30
            fi
        done
    fi
    
    # è·å–OpenSearchç«¯ç‚¹
    OPENSEARCH_ENDPOINT=$(aws opensearch describe-domain --domain-name $DOMAIN_NAME --region $REGION --query 'DomainStatus.Endpoint' --output text)
    export OPENSEARCH_ENDPOINT
    
    log_info "ğŸ“Š OpenSearchåŸŸä¿¡æ¯ï¼š"
    log_info "  ç«¯ç‚¹: https://$OPENSEARCH_ENDPOINT"
    log_info "  Dashboard: https://$OPENSEARCH_ENDPOINT/_dashboards"
    log_info "  ç”¨æˆ·å: admin"
    log_info "  å¯†ç : $OPENSEARCH_PASSWORD"
    log_info "  è®¿é—®æ–¹å¼: éœ€è¦ç”¨æˆ·åå¯†ç è®¤è¯"
    log_info "  å¼•æ“ç‰ˆæœ¬: OpenSearch 2.19"
    log_info "  å®ä¾‹é…ç½®: 3 x r7g.large.search"
    log_info "  å­˜å‚¨é…ç½®: 300 GiB GP3"
}

# 5. éƒ¨ç½²Fluent-bit
deploy_fluent_bit() {
    log_info "æ­¥éª¤5: éƒ¨ç½²Fluent-bitæ—¥å¿—é‡‡é›†..."
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»é€šè¿‡eksctlé…ç½®äº†æœåŠ¡è´¦æˆ·
    if kubectl get serviceaccount fluent-bit -n amazon-cloudwatch >/dev/null 2>&1; then
        log_info "Fluent-bitæœåŠ¡è´¦æˆ·å·²å­˜åœ¨ï¼ˆé€šè¿‡eksctlé…ç½®ï¼‰"
    else
        # æ‰‹åŠ¨åˆ›å»ºFluent-bit IAMè§’è‰²ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        log_info "åˆ›å»ºFluent-bit IAMè§’è‰²..."
        
        eksctl create iamserviceaccount \
            --cluster=logs-collect-cluster \
            --namespace=amazon-cloudwatch \
            --name=fluent-bit \
            --role-name FluentBitRole \
            --attach-policy-arn=arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy \
            --approve || true
    fi
    
    # ç¡®ä¿å‘½åç©ºé—´å­˜åœ¨
    kubectl create namespace amazon-cloudwatch --dry-run=client -o yaml | kubectl apply -f -
    
    # éƒ¨ç½²Fluent-bit
    log_info "éƒ¨ç½²Fluent-bité…ç½®..."
    envsubst < fluent-bit-config.yaml | kubectl apply -f -
    
    # ç­‰å¾…Fluent-bitå°±ç»ª
    log_info "ç­‰å¾…Fluent-bit Podå°±ç»ª..."
    kubectl wait --for=condition=ready pod -l k8s-app=fluent-bit -n amazon-cloudwatch --timeout=300s
    
    # éªŒè¯Fluent-bitçŠ¶æ€
    log_info "éªŒè¯Fluent-bitçŠ¶æ€..."
    kubectl get pods -n amazon-cloudwatch
    kubectl logs -n amazon-cloudwatch -l k8s-app=fluent-bit --tail=10
    
    log_success "Fluent-bitéƒ¨ç½²å®Œæˆ"
}

# æ˜¾ç¤ºè®¿é—®ä¿¡æ¯
show_access_info() {
    log_info "è·å–è®¿é—®ä¿¡æ¯..."
    
    # è·å–ALBåœ°å€
    ALB_ADDRESS=$(kubectl get ingress logs-collect-ingress -n logs-collect -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "æ­£åœ¨åˆ›å»ºä¸­...")
    
    echo ""
    log_success "=== éƒ¨ç½²å®Œæˆ ==="
    echo ""
    echo "ğŸ“Š è®¿é—®ä¿¡æ¯ï¼š"
    echo "  ğŸŒ æµ‹è¯•åº”ç”¨: https://logs-collect.$DOMAIN_NAME"
    echo "  ğŸ“ˆ OpenSearch Dashboard: https://$OPENSEARCH_ENDPOINT/_dashboards"
    echo "  ğŸ‘¤ ç”¨æˆ·å: admin"
    echo "  ğŸ”‘ å¯†ç : $OPENSEARCH_PASSWORD"
    echo ""
    echo "ğŸ”§ ALBä¿¡æ¯ï¼š"
    echo "  ğŸ“ ALBåœ°å€: $ALB_ADDRESS"
    echo ""
    echo "ğŸ“‹ åç»­æ­¥éª¤ï¼š"
    echo "  1. åœ¨Route53ä¸­æ·»åŠ CNAMEè®°å½•ï¼š"
    echo "     åç§°: logs-collect.$DOMAIN_NAME"
    echo "     å€¼: $ALB_ADDRESS"
    echo ""
    echo "  2. è®¿é—®OpenSearch Dashboardé…ç½®ç´¢å¼•æ¨¡å¼"
    echo "  3. æŸ¥çœ‹å®æ—¶æ—¥å¿—æ•°æ®"
    echo ""
    echo "ğŸ” éªŒè¯å‘½ä»¤ï¼š"
    echo "  kubectl get pods -n logs-collect"
    echo "  kubectl get pods -n amazon-cloudwatch"
    echo "  kubectl logs -f -n logs-collect deployment/log-generator"
}

# ä¸»å‡½æ•°
main() {
    echo "ğŸš€ å¼€å§‹éƒ¨ç½² Logs Collect é¡¹ç›®..."
    echo ""
    
    check_env_vars
    check_tools
    
    create_eks_cluster
    deploy_test_app
    deploy_alb_ingress
    create_opensearch_domain
    deploy_fluent_bit
    
    show_access_info
    
    log_success "ğŸ‰ æ‰€æœ‰ç»„ä»¶éƒ¨ç½²å®Œæˆï¼"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
